{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\python39\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: sklearn in d:\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: transformers in d:\\python39\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: pandas in d:\\python39\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in d:\\python39\\lib\\site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in d:\\python39\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in d:\\python39\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: networkx in d:\\python39\\lib\\site-packages (from torch) (2.8.6)\n",
      "Requirement already satisfied: jinja2 in d:\\python39\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in d:\\python39\\lib\\site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: scikit-learn in d:\\python39\\lib\\site-packages (from sklearn) (1.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in d:\\python39\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\python39\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\python39\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\python39\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\python39\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in d:\\python39\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in d:\\python39\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\python39\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\python39\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\python39\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\python39\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in d:\\python39\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\python39\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python39\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python39\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python39\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python39\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\python39\\lib\\site-packages (from scikit-learn->sklearn) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\python39\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch sklearn transformers pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8570884657634c19a5a52f9edb66e8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee83be48a8a4f478e12328aa9a83f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert = BertModel.from_pretrained('bert-base-uncased', cache_dir='./bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_text(text):\n",
    "    return tokenizer(text, padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_ids'] = df['pattern'].apply(lambda x: tokenize_text(x)['input_ids'][0])\n",
    "df['attention_mask'] = df['pattern'].apply(lambda x: tokenize_text(x)['attention_mask'][0])\n",
    "\n",
    "# Convert labels to numerical values\n",
    "labels = df['tag'].unique()\n",
    "label_dict = {label: idx for idx, label in enumerate(labels)}\n",
    "df['label'] = df['tag'].map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>pattern</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tindakan_stunting</td>\n",
       "      <td>Gimana cara mengatasi kalau anak terdeteksi st...</td>\n",
       "      <td>[tensor(101), tensor(21025), tensor(24805), te...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tindakan_stunting</td>\n",
       "      <td>Apa langkah pertama yang harus diambil kalau a...</td>\n",
       "      <td>[tensor(101), tensor(9706), tensor(2050), tens...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tindakan_stunting</td>\n",
       "      <td>Apa yang harus dilakukan orang tua kalau anakn...</td>\n",
       "      <td>[tensor(101), tensor(9706), tensor(2050), tens...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tindakan_stunting</td>\n",
       "      <td>Bagaimana cara membantu anak yang sudah terlan...</td>\n",
       "      <td>[tensor(101), tensor(4524), tensor(4886), tens...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tindakan_stunting</td>\n",
       "      <td>Apa aja tindakan yang bisa dilakukan kalau ana...</td>\n",
       "      <td>[tensor(101), tensor(9706), tensor(2050), tens...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tag                                            pattern  \\\n",
       "0  tindakan_stunting  Gimana cara mengatasi kalau anak terdeteksi st...   \n",
       "1  tindakan_stunting  Apa langkah pertama yang harus diambil kalau a...   \n",
       "2  tindakan_stunting  Apa yang harus dilakukan orang tua kalau anakn...   \n",
       "3  tindakan_stunting  Bagaimana cara membantu anak yang sudah terlan...   \n",
       "4  tindakan_stunting  Apa aja tindakan yang bisa dilakukan kalau ana...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [tensor(101), tensor(21025), tensor(24805), te...   \n",
       "1  [tensor(101), tensor(9706), tensor(2050), tens...   \n",
       "2  [tensor(101), tensor(9706), tensor(2050), tens...   \n",
       "3  [tensor(101), tensor(4524), tensor(4886), tens...   \n",
       "4  [tensor(101), tensor(9706), tensor(2050), tens...   \n",
       "\n",
       "                                      attention_mask  label  \n",
       "0  [tensor(1), tensor(1), tensor(1), tensor(1), t...      0  \n",
       "1  [tensor(1), tensor(1), tensor(1), tensor(1), t...      0  \n",
       "2  [tensor(1), tensor(1), tensor(1), tensor(1), t...      0  \n",
       "3  [tensor(1), tensor(1), tensor(1), tensor(1), t...      0  \n",
       "4  [tensor(1), tensor(1), tensor(1), tensor(1), t...      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze BERT model parameters to avoid training them\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the seq2seq model with BERT fine-tuning\n",
    "class Seq2SeqClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_dim, output_dim):\n",
    "        super(Seq2SeqClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc = nn.Linear(bert_model.config.hidden_size, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        hidden = self.relu(self.fc(pooled_output))\n",
    "        hidden = self.dropout(hidden)\n",
    "        output = self.out(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_dim = 128\n",
    "output_dim = 36\n",
    "learning_rate = 2e-5\n",
    "batch_size = 16\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model, loss function, and optimizer\n",
    "model = Seq2SeqClassifier(bert, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "input_ids = torch.stack(df['input_ids'].tolist())\n",
    "attention_masks = torch.stack(df['attention_mask'].tolist())\n",
    "labels = torch.tensor(df['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 36 4\n"
     ]
    }
   ],
   "source": [
    "# Verify the number of unique labels\n",
    "labels = df['tag'].unique()\n",
    "label_dict = {label: idx for idx, label in enumerate(labels)}\n",
    "df['label'] = df['tag'].map(label_dict)\n",
    "\n",
    "# Number of unique labels\n",
    "num_labels = len(labels)\n",
    "print(f\"Number of unique labels: {num_labels} {output_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 3.5697, Accuracy: 0.0575\n",
      "Epoch 2/10, Loss: 3.5676, Accuracy: 0.0481\n",
      "Epoch 3/10, Loss: 3.5666, Accuracy: 0.0497\n",
      "Epoch 4/10, Loss: 3.5620, Accuracy: 0.0512\n",
      "Epoch 5/10, Loss: 3.5707, Accuracy: 0.0606\n",
      "Epoch 6/10, Loss: 3.5568, Accuracy: 0.0419\n",
      "Epoch 7/10, Loss: 3.5632, Accuracy: 0.0575\n",
      "Epoch 8/10, Loss: 3.5696, Accuracy: 0.0497\n",
      "Epoch 9/10, Loss: 3.5647, Accuracy: 0.0481\n",
      "Epoch 10/10, Loss: 3.5589, Accuracy: 0.0543\n",
      "Epoch 11/10, Loss: 3.5607, Accuracy: 0.0512\n",
      "Epoch 12/10, Loss: 3.5570, Accuracy: 0.0543\n",
      "Epoch 13/10, Loss: 3.5597, Accuracy: 0.0637\n",
      "Epoch 14/10, Loss: 3.5528, Accuracy: 0.0466\n",
      "Epoch 15/10, Loss: 3.5588, Accuracy: 0.0435\n",
      "Epoch 16/10, Loss: 3.5531, Accuracy: 0.0683\n",
      "Epoch 17/10, Loss: 3.5564, Accuracy: 0.0637\n",
      "Epoch 18/10, Loss: 3.5522, Accuracy: 0.0512\n",
      "Epoch 19/10, Loss: 3.5529, Accuracy: 0.0481\n",
      "Epoch 20/10, Loss: 3.5608, Accuracy: 0.0512\n",
      "Epoch 21/10, Loss: 3.5575, Accuracy: 0.0637\n",
      "Epoch 22/10, Loss: 3.5487, Accuracy: 0.0637\n",
      "Epoch 23/10, Loss: 3.5512, Accuracy: 0.0637\n",
      "Epoch 24/10, Loss: 3.5505, Accuracy: 0.0512\n",
      "Epoch 25/10, Loss: 3.5579, Accuracy: 0.0668\n",
      "Epoch 26/10, Loss: 3.5484, Accuracy: 0.0419\n",
      "Epoch 27/10, Loss: 3.5494, Accuracy: 0.0575\n",
      "Epoch 28/10, Loss: 3.5505, Accuracy: 0.0575\n",
      "Epoch 29/10, Loss: 3.5541, Accuracy: 0.0637\n",
      "Epoch 30/10, Loss: 3.5485, Accuracy: 0.0466\n",
      "Epoch 31/10, Loss: 3.5488, Accuracy: 0.0497\n",
      "Epoch 32/10, Loss: 3.5445, Accuracy: 0.0730\n",
      "Epoch 33/10, Loss: 3.5487, Accuracy: 0.0590\n",
      "Epoch 34/10, Loss: 3.5467, Accuracy: 0.0435\n",
      "Epoch 35/10, Loss: 3.5395, Accuracy: 0.0730\n",
      "Epoch 36/10, Loss: 3.5448, Accuracy: 0.0652\n",
      "Epoch 37/10, Loss: 3.5354, Accuracy: 0.0606\n",
      "Epoch 38/10, Loss: 3.5331, Accuracy: 0.0543\n",
      "Epoch 39/10, Loss: 3.5295, Accuracy: 0.0606\n",
      "Epoch 40/10, Loss: 3.5346, Accuracy: 0.0652\n",
      "Epoch 41/10, Loss: 3.5423, Accuracy: 0.0590\n",
      "Epoch 42/10, Loss: 3.5395, Accuracy: 0.0621\n",
      "Epoch 43/10, Loss: 3.5335, Accuracy: 0.0745\n",
      "Epoch 44/10, Loss: 3.5370, Accuracy: 0.0621\n",
      "Epoch 45/10, Loss: 3.5406, Accuracy: 0.0652\n",
      "Epoch 46/10, Loss: 3.5376, Accuracy: 0.0637\n",
      "Epoch 47/10, Loss: 3.5318, Accuracy: 0.0528\n",
      "Epoch 48/10, Loss: 3.5291, Accuracy: 0.0575\n",
      "Epoch 49/10, Loss: 3.5284, Accuracy: 0.0683\n",
      "Epoch 50/10, Loss: 3.5417, Accuracy: 0.0606\n",
      "Epoch 51/10, Loss: 3.5297, Accuracy: 0.0575\n",
      "Epoch 52/10, Loss: 3.5264, Accuracy: 0.0621\n",
      "Epoch 53/10, Loss: 3.5215, Accuracy: 0.0590\n",
      "Epoch 54/10, Loss: 3.5343, Accuracy: 0.0590\n",
      "Epoch 55/10, Loss: 3.5288, Accuracy: 0.0621\n",
      "Epoch 56/10, Loss: 3.5236, Accuracy: 0.0652\n",
      "Epoch 57/10, Loss: 3.5304, Accuracy: 0.0590\n",
      "Epoch 58/10, Loss: 3.5307, Accuracy: 0.0606\n",
      "Epoch 59/10, Loss: 3.5357, Accuracy: 0.0543\n",
      "Epoch 60/10, Loss: 3.5219, Accuracy: 0.0543\n",
      "Epoch 61/10, Loss: 3.5335, Accuracy: 0.0730\n",
      "Epoch 62/10, Loss: 3.5214, Accuracy: 0.0714\n",
      "Epoch 63/10, Loss: 3.5243, Accuracy: 0.0606\n",
      "Epoch 64/10, Loss: 3.5277, Accuracy: 0.0668\n",
      "Epoch 65/10, Loss: 3.5261, Accuracy: 0.0637\n",
      "Epoch 66/10, Loss: 3.5234, Accuracy: 0.0621\n",
      "Epoch 67/10, Loss: 3.5272, Accuracy: 0.0668\n",
      "Epoch 68/10, Loss: 3.5316, Accuracy: 0.0714\n",
      "Epoch 69/10, Loss: 3.5278, Accuracy: 0.0652\n",
      "Epoch 70/10, Loss: 3.5098, Accuracy: 0.0683\n",
      "Epoch 71/10, Loss: 3.5333, Accuracy: 0.0652\n",
      "Epoch 72/10, Loss: 3.5126, Accuracy: 0.0637\n",
      "Epoch 73/10, Loss: 3.5168, Accuracy: 0.0606\n",
      "Epoch 74/10, Loss: 3.5192, Accuracy: 0.0668\n"
     ]
    }
   ],
   "source": [
    "# Training loop with fine-tuning\n",
    "for epoch in range(128):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels).item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct_predictions / len(df)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.0543\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels).item()\n",
    "\n",
    "    accuracy = correct_predictions / len(data_loader.dataset)\n",
    "    return accuracy\n",
    "\n",
    "# Create a DataLoader for the evaluation\n",
    "eval_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Calculate the accuracy\n",
    "final_accuracy = evaluate_model(model, eval_loader)\n",
    "print(f\"Final Accuracy: {final_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
